{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_K-kcpeGxgCi"},"outputs":[],"source":["!pip install segmentation-models-pytorch"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31596,"status":"ok","timestamp":1717315612203,"user":{"displayName":"Zayyan Naveed","userId":"13655979348963378111"},"user_tz":-480},"id":"-LQgS-s_xlOH","outputId":"bccbfcb1-9da1-4187-d4ae-dc7d1cff2b0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":672,"status":"ok","timestamp":1717322861913,"user":{"displayName":"Zayyan Naveed","userId":"13655979348963378111"},"user_tz":-480},"id":"Jg8VcMvMxlry"},"outputs":[],"source":["import os\n","import sys\n","\n","GOOGLE_DRIVE_PATH = \"path/to/your/google/drive/folder/\"\n","sys.path.append(GOOGLE_DRIVE_PATH)"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1717322863435,"user":{"displayName":"Zayyan Naveed","userId":"13655979348963378111"},"user_tz":-480},"id":"0z3_NLIXxs7o"},"outputs":[],"source":["import os\n","import glob\n","import numpy as np\n","from PIL import Image\n","import torch\n","from torch.utils.data import DataLoader, Dataset, Subset\n","from sklearn.model_selection import KFold\n","import segmentation_models_pytorch as smp"]},{"cell_type":"code","execution_count":68,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1717322863435,"user":{"displayName":"Zayyan Naveed","userId":"13655979348963378111"},"user_tz":-480},"id":"N7A3c-rDx31O"},"outputs":[],"source":["class CityscapesDataset(Dataset):\n","    def __init__(self, images, targets, preprocessing=None, transform=None, target_transform=None):\n","        self.images = images\n","        self.targets = targets\n","        self.preprocessing = preprocessing\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, index):\n","        img_path = self.images[index]\n","        label_path = self.targets[index]\n","\n","        image = Image.open(img_path).convert('RGB')\n","        label = Image.open(label_path).convert('L')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        if self.preprocessing:\n","            image = self.preprocessing(np.array(image))\n","            image = torch.tensor(image).permute(2, 0, 1).float()\n","\n","        if self.target_transform:\n","            label = self.target_transform(label)\n","        else:\n","            label = torch.tensor(np.array(label), dtype=torch.long)\n","\n","        return image, label"]},{"cell_type":"code","execution_count":69,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717322864253,"user":{"displayName":"Zayyan Naveed","userId":"13655979348963378111"},"user_tz":-480},"id":"2flm7QFzyNFU"},"outputs":[],"source":["preprocessing_fn = smp.encoders.get_preprocessing_fn(\"resnet34\", \"imagenet\")"]},{"cell_type":"code","execution_count":70,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717322864254,"user":{"displayName":"Zayyan Naveed","userId":"13655979348963378111"},"user_tz":-480},"id":"RJDu0DsXyTkv"},"outputs":[],"source":["def get_data_filepaths(root, split):\n","    images = sorted(glob.glob(os.path.join(root, 'leftImg8bit', split, '**', '*_leftImg8bit.png'), recursive=True))\n","    targets = sorted(glob.glob(os.path.join(root, 'gtFine', split, '**', '*_gtFine_labelTrainIds.png'), recursive=True))\n","    return images, targets"]},{"cell_type":"code","execution_count":83,"metadata":{"executionInfo":{"elapsed":9502,"status":"ok","timestamp":1717329742951,"user":{"displayName":"Zayyan Naveed","userId":"13655979348963378111"},"user_tz":-480},"id":"CBYi1Q0dyUKe"},"outputs":[],"source":["dataset_path = os.path.join(GOOGLE_DRIVE_PATH, 'cityscapes')\n","\n","train_images, train_targets = get_data_filepaths(dataset_path, 'train')\n","val_images, val_targets = get_data_filepaths(dataset_path, 'val')\n","\n","images = train_images + val_images\n","targets = train_targets + val_targets"]},{"cell_type":"code","execution_count":85,"metadata":{"executionInfo":{"elapsed":629,"status":"ok","timestamp":1717329753070,"user":{"displayName":"Zayyan Naveed","userId":"13655979348963378111"},"user_tz":-480},"id":"n7ppuVtNyknP"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""]},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1248,"status":"ok","timestamp":1717329759419,"user":{"displayName":"Zayyan Naveed","userId":"13655979348963378111"},"user_tz":-480},"id":"dVftiRZ2VKFb","outputId":"127e7c65-ea94-4b21-ac9a-55373d85d1f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 1\n","Fold 2\n","Fold 3\n","Fold 4\n","Fold 5\n"]}],"source":["train_datasets = []\n","val_datasets = []\n","kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","for fold, (train_idx, val_idx) in enumerate(kfold.split(images)):\n","    train_images = [images[i] for i in train_idx]\n","    train_targets = [targets[i] for i in train_idx]\n","    val_images = [images[i] for i in val_idx]\n","    val_targets = [targets[i] for i in val_idx]\n","\n","    train_datasets.append(CityscapesDataset(train_images, train_targets, preprocessing=preprocessing_fn))\n","    val_datasets.append(CityscapesDataset(val_images, val_targets, preprocessing=preprocessing_fn))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J4ze9gMDyntO"},"outputs":[],"source":["for fold in range(5):\n","    print(f'Fold {fold+1}')\n","\n","    train_dataset = train_datasets[fold]\n","    val_dataset = val_datasets[fold]\n","\n","    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=8)\n","    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)\n","\n","    model = smp.Unet(\n","        encoder_name=\"resnet34\",\n","        encoder_weights=\"imagenet\",\n","        classes=19,\n","        activation=None\n","    )\n","    model = model.to(device)\n","\n","    criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","    best_val_loss = float('inf')\n","    model_file_path = os.path.join(GOOGLE_DRIVE_PATH, f'segmentation_fold{fold+1}.pth')\n","\n","    num_epochs = 10\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for images, labels in train_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(train_loader)}\")\n","\n","        model.eval()\n","        val_loss = 0.0\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","        average_val_loss = val_loss / len(val_loader)\n","        print(f'Validation Loss: {average_val_loss}')\n","\n","        if average_val_loss < best_val_loss:\n","            best_val_loss = average_val_loss\n","            torch.save(model, model_file_path)\n","            print(f'Current best model saved with validation loss: {best_val_loss}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ul0mbbHyPQF-"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP2GbrY20+524dkx3JT1NFY","gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
